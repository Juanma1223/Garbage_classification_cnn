{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2390 files belonging to 5 classes.\n",
      "Using 1912 files for training.\n",
      "Found 2390 files belonging to 5 classes.\n",
      "Using 478 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 14:41:20.920984: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import datetime\n",
    "\n",
    "dataDir = \"/code/archive/garbage_classification/Garbage_classification\"\n",
    "\n",
    "imgHeight = 224\n",
    "imgWidth = 224\n",
    "batchSize = 32\n",
    "\n",
    "trainDs = tf.keras.utils.image_dataset_from_directory(\n",
    "  dataDir,\n",
    "  validation_split=0.2,\n",
    "  labels='inferred'\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(imgHeight, imgWidth),\n",
    "  batch_size=batchSize)\n",
    "\n",
    "valDs = tf.keras.utils.image_dataset_from_directory(\n",
    "  dataDir,\n",
    "  validation_split=0.2,\n",
    "  labels='inferred'\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(imgHeight, imgWidth),\n",
    "  batch_size=batchSize)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "inception_v3 = \"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\"\n",
    "\n",
    "feature_extractor_model = mobilenet_v2\n",
    "\n",
    "IMAGE_SHAPE = (imgHeight, imgWidth)\n",
    "\n",
    "# Apply normalization to images\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "trainDs = trainDs.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "valDs = valDs.map(lambda x, y: (normalization_layer(x), y)) # Where x—images, y—labels.\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "trainDs = trainDs.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valDs = valDs.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  tf.keras.layers.Resizing(imgHeight,imgWidth),\n",
    "])\n",
    "\n",
    "feature_extractor_layer = hub.KerasLayer(\n",
    "    feature_extractor_model,\n",
    "    input_shape=(imgHeight, imgWidth, 3),\n",
    "    trainable=False)\n",
    "\n",
    "feature_extractor_layer.trainable = False\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  resize_and_rescale,\n",
    "  data_augmentation,\n",
    "  feature_extractor_layer,\n",
    "  tf.keras.layers.Dropout(0.3),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(256, activation='relu'),\n",
    "  tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.Adam(),\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['acc'])\n",
    "# model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "/usr/local/lib/python3.8/dist-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "2022-12-06 14:41:41.117169: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154140672 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/60 [..............................] - ETA: 6:24 - loss: 1.9174 - acc: 0.2188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 14:41:41.698899: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154140672 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/60 [>.............................] - ETA: 31s - loss: 1.8101 - acc: 0.2812 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 14:41:42.204349: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154140672 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/60 [>.............................] - ETA: 31s - loss: 1.7469 - acc: 0.3333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 14:41:42.776867: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154140672 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/60 [=>............................] - ETA: 30s - loss: 1.6811 - acc: 0.3359"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 14:41:43.251389: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 154140672 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 42s 600ms/step - loss: 0.7719 - acc: 0.7066 - val_loss: 0.4540 - val_acc: 0.8452\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 33s 553ms/step - loss: 0.4541 - acc: 0.8279 - val_loss: 0.4179 - val_acc: 0.8556\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 30s 502ms/step - loss: 0.3730 - acc: 0.8572 - val_loss: 0.4312 - val_acc: 0.8431\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 32s 530ms/step - loss: 0.3311 - acc: 0.8703 - val_loss: 0.4389 - val_acc: 0.8431\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 33s 554ms/step - loss: 0.3145 - acc: 0.8813 - val_loss: 0.4058 - val_acc: 0.8745\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 34s 562ms/step - loss: 0.2880 - acc: 0.8870 - val_loss: 0.4222 - val_acc: 0.8431\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 33s 555ms/step - loss: 0.2587 - acc: 0.9064 - val_loss: 0.4404 - val_acc: 0.8515\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 33s 547ms/step - loss: 0.2374 - acc: 0.9074 - val_loss: 0.3567 - val_acc: 0.8745\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 33s 550ms/step - loss: 0.2094 - acc: 0.9252 - val_loss: 0.3740 - val_acc: 0.8745\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 34s 563ms/step - loss: 0.2151 - acc: 0.9179 - val_loss: 0.3979 - val_acc: 0.8536\n"
     ]
    }
   ],
   "source": [
    "# Fit model\n",
    "\n",
    "history = model.fit(trainDs,\n",
    "epochs=10,\n",
    "validation_data=valDs)\n",
    "\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# plt.plot(history.history['val_accuracy'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n",
      "[[2.3769098e-03 3.5051882e-02 1.8862981e-03 2.6233474e-04 9.6042252e-01]]\n",
      "Max probability 0.9604225\n",
      "Predicted index 4\n",
      "Predicted class: Plastic\n",
      "0.999999940773705\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "model.save('./saved_mode/garbage_class.h5')\n",
    "# img = Image.open(\"/code/test_images/plastic_bottle_1.jpg\").convert('L').resize((imgWidth,imgHeight), Image.ANTIALIAS)\n",
    "# img = np.array(img)\n",
    "# print(img.shape())\n",
    "\n",
    "img = tf.io.read_file(\"/code/test_images/plastic_bottle_2.jpg\")\n",
    "tensor = tf.io.decode_image(img, channels=3, dtype=tf.dtypes.float32)\n",
    "tensor = tf.image.resize(tensor, [imgHeight, imgWidth])\n",
    "input_tensor = tf.expand_dims(tensor, axis=0)\n",
    "\n",
    "prediction = model.predict(input_tensor)\n",
    "print(prediction)\n",
    "maxValue = max(prediction[0])\n",
    "print(\"Max probability\",maxValue)\n",
    "\n",
    "# Set classes labels\n",
    "classes = ['Cardboard','Glass','Metal','Paper','Plastic']\n",
    "\n",
    "print(\"Predicted index\",np.where(prediction[0] == maxValue)[0][0])\n",
    "print(\"Predicted class:\",classes[np.where(prediction[0] == maxValue)[0][0]])\n",
    "print(sum(prediction[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
